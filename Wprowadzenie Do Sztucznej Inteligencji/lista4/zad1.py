# ==========================
# Implementacja algorytmu KMeans
# ==========================

# Algorytm KMeans - dziaanie krok po kroku:
# 1. Losowo wybierz centroidy (z preferencj do rozproszenia - metoda podobna do KMeans++).
# 2. Przypisz ka偶dy punkt do najbli偶szego centroidu (przypisanie do klastra).
# 3. Oblicz nowe centroidy jako rednie punkt贸w w ka偶dym klastrze.
# 4. Sprawd藕 warunek stopu - jeli centroidy prawie si nie przesuwaj, zakocz.
# 5. Oblicz bezwadno (suma odlegoci punkt贸w od centroid贸w) - ocena jakoci modelu.
# 6. Powtarzaj algorytm kilka razy z r贸偶nymi pocztkami, wybierz najlepszy model (z najni偶sz bezwadnoci).

class KMeans:
    def __init__(self, n_clusters=8, max_iter=30, tol=1e-4, random_state=None):
        self.n_clusters = n_clusters  # liczba klastr贸w
        self.max_iter = max_iter  # maksymalna liczba iteracji
        self.tol = tol  # tolerancja dla zatrzymania (pr贸g ruchu centroid贸w)
        self.random_state = random_state
        self.centroids = None
        self.cluster_assignments = None
        self.inertia = None  # suma odlegoci punkt贸w od centroid贸w

    # Obliczanie odlegoci euklidesowej punktu od wszystkich centroid贸w
    def _euclidean_distance(self, point, centroids):
        return np.sqrt(np.sum((point - centroids) ** 2, axis=1))

    # Inicjalizacja centroid贸w (losowo, inspirowana KMeans++)
    def _initialize_centroids(self, data):
        if self.random_state is not None:
            np.random.seed(self.random_state)

        n_samples, n_features = data.shape
        centroids = np.zeros((self.n_clusters, n_features))
        centroids[0] = data[np.random.choice(n_samples)]  # pierwszy centroid losowo

        for k in range(1, self.n_clusters):
            distances_matrix = np.sqrt(np.sum((data[:, np.newaxis, :] - centroids[:k]) ** 2, axis=2))
            min_distances = np.min(distances_matrix ** 2, axis=1)

            # Im dalej punkt od istniejcych centroid贸w, tym wiksza szansa na jego wyb贸r
            probabilities = min_distances / np.sum(min_distances) if np.sum(min_distances) != 0 else np.ones_like(min_distances) / len(min_distances)
            centroids[k] = data[np.random.choice(n_samples, p=probabilities)]

        return centroids

    # Przypisanie punkt贸w do najbli偶szego centroidu
    def _assign_to_clusters(self, data):
        assignments = np.zeros(data.shape[0], dtype=int)
        for i, point in enumerate(data):
            distances = self._euclidean_distance(point, self.centroids)
            assignments[i] = np.argmin(distances)
        return assignments

    # Aktualizacja centroid贸w jako rednich punkt贸w w klastrze
    def _update_centroids(self, data, cluster_assignments):
        new_centroids = np.zeros_like(self.centroids)
        for i in range(self.n_clusters):
            points = data[cluster_assignments == i]
            if len(points) > 0:
                new_centroids[i] = np.mean(points, axis=0)
            else:
                new_centroids[i] = self.centroids[i]  # centroid zostaje jeli nie ma punkt贸w
        return new_centroids

    #  (e) Obliczanie bezwadnoci - suma odlegoci punkt贸w od centroid贸w
    def _calculate_inertia(self, data, cluster_assignments):
        inertia = 0.0
        for i in range(self.n_clusters):
            points = data[cluster_assignments == i]
            inertia += np.sum((points - self.centroids[i]) ** 2)
        return inertia

    # G贸wna ptla algorytmu KMeans
    def fit(self, data):
        self.centroids = self._initialize_centroids(data)
        for _ in range(self.max_iter):
            old_centroids = self.centroids.copy()
            self.cluster_assignments = self._assign_to_clusters(data)
            self.centroids = self._update_centroids(data, self.cluster_assignments)

            #  (d) Sprawdzenie warunku stopu - jeli centroidy przesuwaj si o mniej ni偶 tol, algorytm si zatrzymuje
            movement = np.sum(np.linalg.norm(self.centroids - old_centroids, axis=1))
            if movement < self.tol:
                break

        #  (e) Obliczenie bezwadnoci po zakoczeniu iteracji
        self.inertia = self._calculate_inertia(data, self.cluster_assignments)
        return self

    # Przypisanie nowych danych do istniejcych centroid贸w
    def predict(self, data):
        return self._assign_to_clusters(data)


# ==========================
# Uruchomienie pr贸b KMeans
# ==========================
def run_k_means_trials(data, labels, n_clusters, num_trials=5):
    best_model = None
    min_inertia = float('inf')

    for trial in range(num_trials):
        model = KMeans(n_clusters=n_clusters, max_iter=300, tol=1e-4, random_state=trial)
        model.fit(data)

        #  Wyb贸r najlepszego modelu - wybieramy ten z najni偶sz bezwadnoci
        if model.inertia < min_inertia:
            best_model = model
            min_inertia = model.inertia

    print(f"K={n_clusters} - Best inertia: {min_inertia:.2f}")
    
    # Wizualizacja wynik贸w najlepszego modelu
    plot_cluster_assignment_matrix(y_true=labels, y_pred=best_model.cluster_assignments, n_clusters=n_clusters, title=f"Digit-cluster assignment (K={n_clusters})")
    visualize_clusters(best_model.centroids, f"Centroids (K={n_clusters})")
    return best_model
